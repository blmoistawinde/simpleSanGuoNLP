{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import jieba\n",
    "import jieba.posseg as pseg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引入知识库，资料从网络上收集并已经加以整理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_data = pd.read_excel(\"name_data.xlsx\",index_col=0)\n",
    "name_data = name_data.set_index(\"姓名\")\n",
    "name_data = name_data.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>姓</th>\n",
       "      <th>名</th>\n",
       "      <th>字</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>姓名</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>丁仪</th>\n",
       "      <td>丁</td>\n",
       "      <td>仪</td>\n",
       "      <td>正礼</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>丁冲</th>\n",
       "      <td>丁</td>\n",
       "      <td>冲</td>\n",
       "      <td>无</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>丁原</th>\n",
       "      <td>丁</td>\n",
       "      <td>原</td>\n",
       "      <td>建阳</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>丁厷</th>\n",
       "      <td>丁</td>\n",
       "      <td>厷</td>\n",
       "      <td>无</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>丁君干</th>\n",
       "      <td>丁</td>\n",
       "      <td>君干</td>\n",
       "      <td>无</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     姓   名   字\n",
       "姓名            \n",
       "丁仪   丁   仪  正礼\n",
       "丁冲   丁   冲   无\n",
       "丁原   丁   原  建阳\n",
       "丁厷   丁   厷   无\n",
       "丁君干  丁  君干   无"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面用过程式的方法演示字典树（实体匹配型）的构造过程。相比我实际应用中的有所简化，更详细的代码和数据可以在我的github上找到：\n",
    "\n",
    "https://github.com/blmoistawinde/simpleSanGuoNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trie_root = {}\n",
    "def build_trie(new_word,entity,trie_root):\n",
    "    trie_node = trie_root\n",
    "    for ch in new_word:\n",
    "        if not ch in trie_node:\n",
    "            trie_node[ch] = {}\n",
    "        trie_node = trie_node[ch]\n",
    "    if not 'leaf' in trie_node:\n",
    "        trie_node['leaf'] = set([entity])    #同一个代称有时会对应多个实体，所以这里的叶结点是集合类型\n",
    "    else:\n",
    "        trie_node['leaf'].add(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "build_trie(\"玄德\",\"刘备\",trie_root)\n",
    "build_trie(\"玄德公\",\"刘备\",trie_root)\n",
    "build_trie(\"刘皇叔\",\"刘备\",trie_root)\n",
    "build_trie(\"刘备\",\"刘备\",trie_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'玄': {'德': {'leaf': {'刘备'}, '公': {'leaf': {'刘备'}}}}, '刘': {'皇': {'叔': {'leaf': {'刘备'}}}, '备': {'leaf': {'刘备'}}}}\n"
     ]
    }
   ],
   "source": [
    "print(trie_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在字典树中查找代称对应的实体。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_trie(word,trie_root):\n",
    "    trie_node = trie_root\n",
    "    for ch in word:\n",
    "        if not ch in trie_node:\n",
    "            return set()\n",
    "        trie_node = trie_node[ch]\n",
    "    if \"leaf\" in trie_node:\n",
    "        return trie_node['leaf']\n",
    "    else:\n",
    "        return set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'刘备'}\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(find_trie(\"刘备\",trie_root))\n",
    "print(find_trie(\"刘备啊\",trie_root))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但这里我需要的其实是把字典树与顺序扫描结合在一起，一边扫描一边识别实体。这样其实我是不能准确得到词语的右边界的。于是我需要另一个函数来完成这个任务，逐字符扫描中深入字典树【每一步暂存当前结点】，直到发现实体（集）或者无法匹配再跳出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dig_trie(sent,l,trie_root):                                #返回实体右边界r,实体范围\n",
    "    trie_node = trie_root\n",
    "    for i in range(l,len(sent)):\n",
    "        if sent[i] in trie_node:\n",
    "            trie_node = trie_node[sent[i]]\n",
    "        else:\n",
    "            if \"leaf\" in trie_node:\n",
    "                return i, trie_node[\"leaf\"]\n",
    "            else:\n",
    "                return -1, set()                                 # -1表示未找到\n",
    "    # 收尾\n",
    "    if \"leaf\" in trie_node:\n",
    "        return len(sent), trie_node[\"leaf\"]\n",
    "    else:\n",
    "        return -1, set()                                 # -1表示未找到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "build_trie(\"刘\",\"666\",trie_root)\n",
    "build_trie(\"刘胜\",\"刘胜\",trie_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1, set())\n",
      "(6, {'刘胜'})\n",
      "(5, {'666'})\n"
     ]
    }
   ],
   "source": [
    "print(dig_trie(\"中山靖王刘胜之后，汉景帝阁下玄孙\",0,trie_root))\n",
    "print(dig_trie(\"中山靖王刘胜之后，汉景帝阁下玄孙\",4,trie_root))          # 不会被单独的刘干扰，除非确实不匹配\n",
    "print(dig_trie(\"中山靖王刘某之后，汉景帝阁下玄孙\",4,trie_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([0, 2], '刘备'), ([3, 5], '刘备'), ([8, 11], '刘备'), ([13, 14], '666')]\n"
     ]
    }
   ],
   "source": [
    "def entity_linking(sent,trie_root):\n",
    "    ret = []\n",
    "    l = 0\n",
    "    while l < len(sent):\n",
    "        r, entities = dig_trie(sent,l,trie_root)\n",
    "        if r != -1:\n",
    "            name0 = sent[l:r]\n",
    "            ret.append(([l,r],list(entities)[0])) #简单起见，在这里如果同一个名称对应多个实体，默认选取第一个，完整版中用了更多消歧方法\n",
    "            l = r\n",
    "        else:\n",
    "            l += 1\n",
    "    return ret\n",
    "sent = \"刘备字玄德，号称刘皇叔，是刘氏又一豪杰\"\n",
    "print(entity_linking(sent,trie_root))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果只是要统计实体的出现次数的话，到这里已经足够，如果再想利用这些知识进行分词的话，还有几步要做。\n",
    "\n",
    "首先，利用我们所有的姓名知识库构建一颗完整的字典树。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names_trie = {}\n",
    "for entity0, line in name_data.iterrows():\n",
    "    for name0 in [line[\"姓\"]+line[\"名\"],line[\"字\"]]:               \n",
    "        if not name0 in [\"无\",\"None\",\"\"] and len(name0) > 1:            \n",
    "            build_trie(name0,entity0,names_trie)\n",
    "    name0  = line[\"姓\"]+line[\"名\"]\n",
    "    if not name0 in [\"无\",\"None\",\"\"] and len(name0) > 1:            # 长度1的名字太容易混淆，不采纳\n",
    "        build_trie(name0,entity0,names_trie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'伯': {'leaf': {'陈泰'}},\n",
       " '冲': {'leaf': {'王浑[西晋]'}},\n",
       " '威': {'leaf': {'胡奋'}},\n",
       " '嶷': {'leaf': {'胡岐'}},\n",
       " '德': {'leaf': {'刘备'}},\n",
       " '方': {'leaf': {'枣腆'}},\n",
       " '武': {'leaf': {'胡烈'}},\n",
       " '胄': {'leaf': {'李秉'}},\n",
       " '通': {'leaf': {'王览'}},\n",
       " '风': {'leaf': {'卜静'}},\n",
       " '骏': {'leaf': {'华澹'}},\n",
       " '默': {'leaf': {'庾倏'}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_trie[\"玄\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关键的一个小操作，指定一个标准词与所有实体联系起来，保证分词工具能够把它分割出来，并且赋予恰当的词性(\"nr\"：人名)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\KELEN\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.811 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "jieba.add_word(\"人占位符\",freq=10000,tag=\"nr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decoref(sent,entities_info):\n",
    "    left = 0\n",
    "    processed_text = \"\"\n",
    "    for (beg,end),entity in entities_info:\n",
    "        print(sent[beg:end],entity)\n",
    "        processed_text += sent[left:beg] + \"人占位符\"\n",
    "        left = end\n",
    "    processed_text += sent[left:]\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "玄德 刘备\n",
      "人占位符幼孤，事母至孝；家贫，贩屦织席为业。\n"
     ]
    }
   ],
   "source": [
    "sent = \"玄德幼孤，事母至孝；家贫，贩屦织席为业。\"\n",
    "entities_info = [([0, 2], '刘备')]\n",
    "print(decoref(sent,entities_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看到这里我们的标准词\"人占位符\"已经替代了识别到的实体的位置，分词时，我们则会把它再换回来，并且提取出了我们设定的词性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def posseg(sent,trie_root):\n",
    "    entities_info = entity_linking(sent,trie_root)\n",
    "    sent2 = decoref(sent,entities_info)\n",
    "    result = []\n",
    "    i = 0\n",
    "    for word, flag in pseg.cut(sent2):\n",
    "        if word == \"人占位符\":\n",
    "            word = entities_info[i][1]\n",
    "            i += 1\n",
    "        result.append((word, flag))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "玄德 刘备\n",
      "[('刘备', 'nr'), ('幼', 'ag'), ('孤', 'ng'), ('，', 'x'), ('事母至孝', 'l'), ('；', 'x'), ('家贫', 'b'), ('，', 'x'), ('贩', 'v'), ('屦', 'g'), ('织', 'v'), ('席为业', 'nr'), ('。', 'x')]\n"
     ]
    }
   ],
   "source": [
    "print(posseg(\"玄德幼孤，事母至孝；家贫，贩屦织席为业。\",names_trie))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "这次第一个“刘备”君被成功地识别了出来。不过还有一个有趣的插曲是，分词工具“识别”出了另一个人名“席为业”。这个问题也可以用我们的知识库解决，毕竟统计的时候只需要统计我们知识库中已经出现的人名就好了吗。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一些数据分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "最后附上一些我基于这个数据做的一些简单分析。为简洁起见，这里只描述结果，不附上代码。\n",
    "\n",
    "将出现在两句话以内的每一对人物添加一条边，统计了整个三国演义的文本后，我们就能够得到一个**三国演义的人物关系网络**。其中，最为频繁的联系包括：\n",
    "\n",
    "- 刘备     诸葛亮    392\n",
    "\n",
    "- 曹操     刘备     257\n",
    "\n",
    "- 刘备     关羽     192\n",
    "\n",
    "- 刘备     张飞     182\n",
    "\n",
    "- 赵云     刘备     177\n",
    "\n",
    "- 司马懿    诸葛亮    150\n",
    "\n",
    "- 诸葛亮    曹操     143\n",
    "\n",
    "- 鲁肃     诸葛亮    143\n",
    "\n",
    "- 魏延     诸葛亮    139\n",
    "\n",
    "- 诸葛亮    赵云     139\n",
    "\n",
    "- 赵云     诸葛亮    139\n",
    "\n",
    "- 孟获     诸葛亮    122\n",
    "\n",
    "对于熟悉三国的朋友，看到这些名字，那些经典章节（桃园结义、三顾茅庐、六出祁山、七擒孟获......）是不是马上涌上心头了呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个网络由于比较庞大，而且也不完全连通，所以用python常用的网络库networkx可视化的效果不佳，这里我尝试了另外一种可视化方法——**node2vec**+**TSNE**，把网络化为了二维散点图，再利用**pyecharts**做成了一个**交互式的散点图**，可以用滚轮放大缩小，鼠标在点上悬停则可以看到人物姓名，这样我们就可以自由探索每个人物在网络中的位置了，感兴趣的朋友，不妨上这里一看:\n",
    "\n",
    "<html>\n",
    "    <a title=\"三国演义人物地图\" href=\"TSNE_node2vec.html\">三国演义人物地图</a>\n",
    "\n",
    "    <a title=\"三国演义人物聚类地图\" href=\"TSNE_node2vec_DBSCAN.html\">三国演义人物聚类地图</a>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里再附上这个网络的**中间中心度**排行，对社交网络分析比较熟悉的朋友应该知道这是一个很适合描述**“权力”**的一个指标。所以我们看到刘备、曹操、孙权、袁绍等主公都名列前茅。而另一个有趣的发现是，司马懿、司马昭、司马师父子三人同样榜上有名，而曹氏的其他后裔则不见其名，所以说，司马氏的权力之大和篡逆之心，似乎就这样被大数据揭示了出来！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 曹操     0.191572\n",
    "\n",
    "- 刘备     0.170507\n",
    "\n",
    "- 诸葛亮    0.154396\n",
    "\n",
    "- 孙权     0.076092\n",
    "\n",
    "- 司马懿    0.057414\n",
    "\n",
    "- 赵云     0.052706\n",
    "\n",
    "- 司马昭    0.045726\n",
    "\n",
    "- 袁绍     0.039813\n",
    "\n",
    "- 吕布     0.032888\n",
    "\n",
    "- 关羽     0.028887\n",
    "\n",
    "- 姜维     0.026319\n",
    "\n",
    "- 马超     0.024139\n",
    "\n",
    "- 丁奉     0.019025\n",
    "\n",
    "- 张翼     0.018943\n",
    "\n",
    "- 邓艾     0.018524\n",
    "\n",
    "- 贾充     0.017374\n",
    "\n",
    "- 司马师    0.017265\n",
    "\n",
    "- 廖化     0.016621\n",
    "\n",
    "- 徐晃     0.016085\n",
    "\n",
    "- 孙策     0.015829"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
